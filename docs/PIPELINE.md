# Complete Pipeline: From Images to Predictions

## ğŸ¯ Overview

This document describes the **complete end-to-end pipeline** from raw street view images to urban perception predictions. The pipeline consists of two main stages:

1. **Feature Extraction** (Optional - pre-computed features provided)
2. **Perception Prediction** (This repository)

## ğŸ“Š Pipeline Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         STAGE 1                                 â”‚
â”‚                   Feature Extraction                            â”‚
â”‚                    (Optional/Reference)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Raw Street View Images                                         â”‚
â”‚  - Urban scenes from Place Pulse 2.0                            â”‚
â”‚  - ~111,268 images                                              â”‚
â”‚  - Various cities worldwide                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                           â”‚
                â†“                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Semantic Segmentation    â”‚   â”‚   Object Detection        â”‚
â”‚  (ADE20K 150 classes)     â”‚   â”‚   (COCO 80 classes)       â”‚
â”‚                           â”‚   â”‚                           â”‚
â”‚  â†’ 26 features            â”‚   â”‚   â†’ 10 features           â”‚
â”‚  (scene composition)      â”‚   â”‚   (discrete objects)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚                           â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  36 or 230 Visual Features      â”‚
                â”‚  per Image               â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         STAGE 2                                 â”‚
â”‚                 Perception Prediction                           â”‚
â”‚                   (This Repository)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Preparation                                               â”‚
â”‚  - Load 36-feature vectors                                      â”‚
â”‚  - Add perception ratings (beautiful, lively, boring, safe)     â”‚
â”‚  - City-based train/test split                                  â”‚
â”‚  - Delta-based label generation                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Delta Sensitivity Analysis                                     â”‚
â”‚  - 7 threshold values (Î´ = 0.5, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8) â”‚
â”‚  - Binary labels: score >= (median + Î´ * std)                  â”‚
â”‚  - Multi-class: Low/Medium/High                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚             â”‚             â”‚              â”‚
                â†“             â†“             â†“              â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Random   â”‚  â”‚   SVM    â”‚  â”‚ XGBoost  â”‚  â”‚ RealMLP  â”‚
        â”‚  Forest  â”‚  â”‚          â”‚  â”‚          â”‚  â”‚    TD    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚             â”‚             â”‚              â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Model Evaluation                                               â”‚
â”‚  - F1 Score, Accuracy, Precision, Recall                        â”‚
â”‚  - ROC-AUC, PR-AUC                                              â”‚
â”‚  - Cross-validation                                             â”‚
â”‚  - Feature importance                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Results & Visualization                                        â”‚
â”‚  - 112 trained models (4 Ã— 7 Ã— 4)                              â”‚
â”‚  - 12+ publication figures                                      â”‚
â”‚  - Comprehensive metrics CSV                                    â”‚
â”‚  - Statistical reports                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â†“
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚  Perception Predictions   â”‚
              â”‚  - Beautiful: 0-10        â”‚
              â”‚  - Lively: 0-10           â”‚
              â”‚  - Boring: 0-10           â”‚
              â”‚  - Safe: 0-10             â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”¢ Data Flow Dimensions

### Stage 1: Feature Extraction

**Input**:
- **Images**: 111,268 street view photos
- **Format**: JPEG/PNG (RGB)
- **Resolution**: Variable (resized to 1024Ã—1024)
- **Size**: ~50GB total

**Processing**:
- **Semantic Segmentation**: 150 classes â†’ 26 features
- **Object Detection**: 80 classes â†’ 10 features
- **Time**: 6-10 hours (GPU) or 3-4 days (CPU)

**Output**:
- **Format**: CSV files (4 files, one per perception)
- **Dimensions**: 111,268 rows Ã— 40 columns
  - 4 metadata columns (ID, path, perception, rating)
  - 36 feature columns
- **Size**: ~300MB total (compressed: ~50MB)

### Stage 2: Perception Prediction

**Input**:
- **Features**: 36 per image
- **Labels**: 4 perception attributes (0-10 scale)
- **Samples**: 111,268 total

**Processing**:
- **Experiments**: 112 (4 perceptions Ã— 7 deltas Ã— 4 models)
- **Split**: 80% train / 20% test (city-based or random)
- **Time**: 2-6 hours for all experiments

**Output**:
- **Models**: 112 trained classifiers
- **Metrics**: F1, Accuracy, ROC-AUC, PR-AUC per experiment
- **Figures**: 12+ publication-ready visualizations
- **Size**: ~500MB (models + results)

## ğŸ“ File Structure & Data Flow

```
Project Root
â”‚
â”œâ”€â”€ Feature_Extraction_Code/           # [STAGE 1 - Optional]
â”‚   â”œâ”€â”€ segmentation_analysis/
â”‚   â”‚   â”œâ”€â”€ extract_ade20k_150_features.py
â”‚   â”‚   â””â”€â”€ output/
â”‚   â”‚       â””â”€â”€ *_ade20k_150_features.csv    # 26 features
â”‚   â”‚
â”‚   â”œâ”€â”€ object_detection_analysis/
â”‚   â”‚   â”œâ”€â”€ extract_detection_features_80_classes.py
â”‚   â”‚   â””â”€â”€ output/
â”‚   â”‚       â””â”€â”€ *_detection_features.csv      # 10 features
â”‚   â”‚
â”‚   â””â”€â”€ merge_features.py                     # Combine â†’ 36 features
â”‚
â”œâ”€â”€ Input_Data/                        # [STAGE 2 INPUT]
â”‚   â””â”€â”€ dinov3_all_classes/            # Example pre-extracted features
â”‚       â”œâ”€â”€ beautiful_input.xlsx       # 111,268 Ã— 40
â”‚       â”œâ”€â”€ lively_input.xlsx          # 111,268 Ã— 40
â”‚       â”œâ”€â”€ boring_input.xlsx          # 111,268 Ã— 40
â”‚       â””â”€â”€ safe_input.xlsx            # 111,268 Ã— 40
â”‚
â”œâ”€â”€ run_experiment.sh                  # [STAGE 2 EXECUTION]
â”‚
â”œâ”€â”€ experiments/                       # [STAGE 2 OUTPUT]
â”‚   â””â”€â”€ <dataset>/<city>/perception_delta_sensitivity_*/
â”‚       â”œâ”€â”€ 02_models/                 # 112 .pkl files
â”‚       â”œâ”€â”€ 03_results/
â”‚       â”‚   â”œâ”€â”€ metrics/
â”‚       â”‚   â”‚   â””â”€â”€ all_results.csv    # 112 rows Ã— 10+ cols
â”‚       â”‚   â””â”€â”€ visualizations/        # 12+ figures
â”‚       â””â”€â”€ experiment_summary.json
â”‚
â””â”€â”€ Feature_Importance/                # [OPTIONAL ANALYSIS]
    â”œâ”€â”€ outputs/
    â”‚   â””â”€â”€ feature_importance_*.csv
    â””â”€â”€ saved_models/
```

## ğŸš€ Quick Start: Complete Pipeline

### Option A: Use Pre-Extracted Features (Recommended)

**Time**: 5 minutes setup + 2-6 hours experiment

```bash
# 1. Setup
cd perception_prediction_gitrepo
source setup_experiment.sh

# 2. Run perception prediction (features already included)
./run_experiment.sh --full --background

# 3. Monitor
./monitor_experiment.sh

# 4. View results
cd experiments/*/03_results/
```

### Option B: Extract Features from Scratch

**Time**: 6-10 hours extraction + 2-6 hours experiment

```bash
# 1. Extract semantic segmentation features
cd Feature_Extraction_Code/segmentation_analysis
./run_ade20k_150_extraction.sh start
# Wait 3-5 hours...

# 2. Extract object detection features (parallel)
cd ../object_detection_analysis
./run_80class_extraction.sh start
# Wait 3-5 hours...

# 3. Merge features
cd ..
python3 merge_features.py \
    --segmentation segmentation_analysis/output/ \
    --detection object_detection_analysis/output/ \
    --output merged_features/

# 4. Format for perception prediction
python3 format_for_perception.py \
    --input merged_features/ \
    --output ../Input_Data/custom_features/

# 5. Run perception prediction
cd ..
export INPUT_DATA_DIR="./Input_Data/custom_features"
./run_experiment.sh --full --background
```

## ğŸ”„ Data Transformations

### 1. Image â†’ Raw Features

**Semantic Segmentation**:
```
Image (1024Ã—1024Ã—3)
    â†’ Segmentation Model
    â†’ Pixel Mask (1024Ã—1024) with 150 classes
    â†’ Count pixels per class
    â†’ Normalize by total pixels
    â†’ Features (150 percentages)
    â†’ Aggregate to 26 semantic categories
```

**Object Detection**:
```
Image (1024Ã—1024Ã—3)
    â†’ Detection Model
    â†’ Bounding Boxes + Labels (N detections Ã— 80 classes)
    â†’ Count objects per class
    â†’ Features (80 counts)
    â†’ Select 10 most relevant urban classes
```

### 2. Features â†’ Labels

**Binary Classification**:
```python
# For each delta value Î´
threshold = median(ratings) + Î´ * std(ratings)
label = 1 if rating >= threshold else 0
```

**Multi-Class Classification**:
```python
low_threshold = median(ratings) - 0.5 * std(ratings)
high_threshold = median(ratings) + 0.5 * std(ratings)

if rating < low_threshold:
    label = "Low"
elif rating < high_threshold:
    label = "Medium"
else:
    label = "High"
```

### 3. Models â†’ Predictions

**Training**:
```python
# For each perception, delta, and model
X_train = features[train_indices]  # 36 features
y_train = labels[train_indices]    # binary or multi-class
model.fit(X_train, y_train)
```

**Prediction**:
```python
# Test set prediction
X_test = features[test_indices]
y_pred = model.predict(X_test)
y_prob = model.predict_proba(X_test)
```

**Evaluation**:
```python
metrics = {
    'f1': f1_score(y_test, y_pred),
    'accuracy': accuracy_score(y_test, y_pred),
    'roc_auc': roc_auc_score(y_test, y_prob[:, 1]),
    'pr_auc': average_precision_score(y_test, y_prob[:, 1])
}
```

## ğŸ“Š Data Quality & Validation

### Feature Extraction Validation

```python
# Check feature ranges
assert (seg_features >= 0).all() and (seg_features <= 100).all()
assert (det_features >= 0).all()

# Check completeness
assert not features.isnull().any()
assert len(features) == expected_count

# Check feature consistency
assert list(features.columns) == expected_feature_names
```

### Perception Prediction Validation

```python
# Check train/test split
assert set(train_ids).isdisjoint(set(test_ids))
assert len(train_ids) + len(test_ids) == total_samples

# Check label distribution
print(f"Positive class: {(labels == 1).sum() / len(labels) * 100:.1f}%")

# Check model performance
assert metrics['accuracy'] > 0.5  # Better than random
```

## âš™ï¸ Configuration Options

### Feature Extraction

```bash
# config.py
IMAGE_DIR = "/path/to/images"
OUTPUT_DIR = "./output"
BATCH_SIZE = 16
USE_GPU = True
SAVE_PROGRESS_EVERY = 100
```

### Perception Prediction

```bash
# run_experiment.sh
INPUT_DATA_DIR="./Input_Data/dinov3_all_classes"
FEATURE_COUNT=36
TEST_CITY_NAME="Mumbai"
USE_CITY_BASED_SPLIT=true

# Run
./run_experiment.sh --full --test-cities Mumbai
```

### Feature Importance

```yaml
# Feature_Importance/experiment_config.yaml
data:
  feature_count: 36
  test_size: 280

perceptions:
  beautiful:
    model: random_forest
    delta: 1.2
```

## ğŸ“ˆ Performance Benchmarks

### Full Pipeline Execution

| Stage | Component | Duration | Resource |
|-------|-----------|----------|----------|
| 1 | Semantic Segmentation | 3-5 hours | GPU (A100) |
| 1 | Object Detection | 3-5 hours | GPU (A100) |
| 1 | Feature Merging | 5-10 min | CPU |
| 2 | Perception Training | 2-6 hours | CPU/GPU |
| 2 | Result Generation | 10-15 min | CPU |
| **Total** | **End-to-End** | **8-16 hours** | **Mixed** |

### Resource Requirements

| Component | CPU | RAM | GPU | Disk |
|-----------|-----|-----|-----|------|
| Feature Extraction | 4+ cores | 16GB | 16GB VRAM | 100GB |
| Perception Prediction | 4+ cores | 8GB | Optional | 5GB |
| Total | 8+ cores | 24GB | 16GB VRAM | 105GB |

## ğŸ”§ Troubleshooting

### Common Issues

**Problem**: Out of GPU memory during feature extraction
```bash
# Solution: Reduce batch size
BATCH_SIZE = 8  # or 4
```

**Problem**: Feature count mismatch
```bash
# Solution: Update feature count
export FEATURE_COUNT=<your_count>
./run_experiment.sh --full
```

**Problem**: City not found in test split
```bash
# Solution: Check valid cities
cat config/cities.yaml
# Or use random split
./run_experiment.sh --full --use-last-280
```

## ğŸ“š Academic Pipeline

For academic publication, we recommend:

### 1. Feature Extraction (Document Thoroughly)
```markdown
- Model: ADE20K Semantic FPN + COCO Faster R-CNN
- Implementation: PyTorch 1.10+
- Hardware: NVIDIA A100 GPU
- Processing time: 6-10 hours
- Code: Available in Feature_Extraction_Code/
```

### 2. Feature Engineering (Report Details)
```markdown
- Input: 150 semantic + 80 detection classes
- Aggregation: Manual grouping based on semantic similarity
- Output: 26 semantic + 10 detection = 36 features
- Normalization: Percentages (0-100) for segmentation, counts for detection
```

### 3. Perception Prediction (Main Contribution)
```markdown
- Models: RF, SVM, XGBoost, RealMLP
- Delta sensitivity: 7 thresholds (0.5-1.8)
- Evaluation: 5-fold cross-validation
- Metrics: F1, Accuracy, ROC-AUC, PR-AUC
```

## ğŸ“– Citation

If you use this complete pipeline, please cite:

```bibtex
@article{yourname2024perception,
  title={Urban Perception Prediction using Delta Sensitivity Analysis},
  author={Your Name and Co-Authors},
  journal={Journal Name},
  year={2024},
  note={Complete pipeline: feature extraction + perception prediction}
}
```

## ğŸ”— Related Documentation

- **Feature Extraction Details**: [FEATURE_EXTRACTION.md](FEATURE_EXTRACTION.md)
- **Perception Prediction**: [README.md](README.md)
- **Quick Start**: [QUICK_START.md](QUICK_START.md)
- **Feature Importance**: [Feature_Importance/feature_importance.md](Feature_Importance/feature_importance.md)

---

**Last Updated**: October 28, 2025
**Version**: 1.0.0
**Pipeline Status**: Production Ready âœ…
